{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "### Machine Learning\n",
    "### Robert Knox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "import time\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_degC</th>\n",
       "      <th>Salnty</th>\n",
       "      <th>STheta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.50</td>\n",
       "      <td>33.440</td>\n",
       "      <td>25.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.46</td>\n",
       "      <td>33.440</td>\n",
       "      <td>25.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.46</td>\n",
       "      <td>33.437</td>\n",
       "      <td>25.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.45</td>\n",
       "      <td>33.420</td>\n",
       "      <td>25.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.45</td>\n",
       "      <td>33.421</td>\n",
       "      <td>25.643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_degC  Salnty  STheta\n",
       "0   10.50  33.440  25.649\n",
       "1   10.46  33.440  25.656\n",
       "2   10.46  33.437  25.654\n",
       "3   10.45  33.420  25.643\n",
       "4   10.45  33.421  25.643"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('bottle.csv') as f:\n",
    "    line = f.readline()\n",
    "line_column_names = line.split(',')\n",
    "\n",
    "desired_cols = ['T_degC','Salnty','STheta']\n",
    "df = pd.read_csv('bottle.csv',sep=',',header='infer',index_col=None,usecols=desired_cols)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_degC    False\n",
       "Salnty    False\n",
       "STheta    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0,inplace=True)\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get values from dataframe\n",
    "T_degC = df['T_degC'].values\n",
    "Salnty = df['Salnty'].values\n",
    "STheta = df['STheta'].values\n",
    "\n",
    "#put the predictors into a corresponding X matrix\n",
    "X = np.column_stack((Salnty,STheta))\n",
    "\n",
    "#Build train & test using sklearn's train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, T_degC, test_size=0.25, random_state=42)\n",
    "\n",
    "#scale the training data\n",
    "scaler_train = StandardScaler(copy=False,with_mean=True, with_std=True)\n",
    "scaler_train.fit(X_train)\n",
    "X_train_scaled = scaler_train.transform(X_train)\n",
    "#scale the testing data using teh same scaler as train\n",
    "X_test_scaled=scaler_train.transform(X_test)\n",
    "\n",
    "#add in the intercepts\n",
    "X_train_b0 = np.ones(len(X_train_scaled))\n",
    "X_test_b0 = np.ones(len(X_test_scaled))\n",
    "X_train_scaled = np.column_stack((X_train_b0,X_train_scaled))\n",
    "X_test_scaled = np.column_stack((X_test_b0,X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203044, 1) \n",
      " (609130, 1) \n",
      " (203044, 3) \n",
      " (609130, 3)\n"
     ]
    }
   ],
   "source": [
    "#deal with list/array issue\n",
    "y_test = np.reshape(y_test,(len(y_test),1))\n",
    "y_train = np.reshape(y_train,(len(y_train),1))\n",
    "\n",
    "#Check that arrays are properly shaped\n",
    "print(y_test.shape,'\\n',y_train.shape,'\\n',X_test_scaled.shape,'\\n',X_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def minibatch_grad_descent(minibatch_size):\n",
    "    np.random.seed(123)\n",
    "    \n",
    "    #begin timing analysis\n",
    "    t0 = time.clock()\n",
    "    m = len(y_train)\n",
    "    epochs = 100\n",
    "    theta = np.random.randn(3,1)  # random initialization of 3 values\n",
    "    \n",
    "    #instantiate predicted y's out here so we can reuse in function\n",
    "    ypred = X_train_scaled.dot(theta)\n",
    "    cost_array = np.zeros(epochs)\n",
    "    gradient_list =[]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        cost = 0.0\n",
    "        #shuffle indices so we start with a random set of data\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "\n",
    "        #get the rows for my shuffled index for both X & y\n",
    "        X_b_shuffled = X_train_scaled[shuffled_indices]\n",
    "        y_shuffled = y_train[shuffled_indices]\n",
    "\n",
    "        #perform batch gradient descent on & do it in chunks of mini-batch size\n",
    "        for i in range(0, m, minibatch_size):\n",
    "            \n",
    "            xi = X_b_shuffled[i:i+minibatch_size]\n",
    "            yi = y_shuffled[i:i+minibatch_size]\n",
    "            pred = xi.dot(theta)\n",
    "            gradients = (2/minibatch_size) * xi.T.dot(xi.dot(theta) - yi)\n",
    "            \n",
    "            eta = 0.1\n",
    "            theta = theta - eta * gradients\n",
    "            gradient_list.append(gradients)\n",
    "            \n",
    "        \n",
    "        #calculate the predictions using our theta from running the minibatch\n",
    "        ypred = X_train_scaled.dot(theta)\n",
    "        MSE = mean_squared_error(y_train,ypred)\n",
    "        cost_array[epoch]=MSE\n",
    "    \n",
    "    #we want to find the gradient_list that performed the best, aka minimized MSE\n",
    "    #Ending time of analysis\n",
    "    t1 = time.clock()\n",
    "    #summarize theta\n",
    "    print('Mini-Batch size:{}\\tEpochs:{}'.format(minibatch_size,epochs))\n",
    "    print('Analysis time:',np.round(t1-t0,4),' seconds')\n",
    "    print('Theta:'+str(theta))\n",
    "    #predict y using X_test_scaled & theta from the loop\n",
    "    ypredtest = X_test_scaled.dot(theta)\n",
    "    #use metrics modules compare yhat to y_test\n",
    "    #RMSE\n",
    "    MSE = mean_squared_error(y_test,ypredtest)\n",
    "    print('MSE:',MSE)\n",
    "    #R2Score\n",
    "    R2score = r2_score(y_test,ypredtest)\n",
    "    print('R2score:',R2score)\n",
    "    #Explained Variance\n",
    "    ExpVar = explained_variance_score(y_test,ypredtest)\n",
    "    print('Explained Variance:',ExpVar)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-Batch size:50\tEpochs:100\n",
      "Analysis time: 22.2021  seconds\n",
      "Theta:[[10.8226751 ]\n",
      " [ 1.43597329]\n",
      " [-6.00573282]]\n",
      "MSE: 4.882304945209515\n",
      "R2score: 0.72553602318795\n",
      "Explained Variance: 0.7255630970772766\n"
     ]
    }
   ],
   "source": [
    "minibatch_grad_descent(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-Batch size:2000\tEpochs:100\n",
      "Analysis time: 12.2394  seconds\n",
      "Theta:[[10.84108761]\n",
      " [ 1.25789214]\n",
      " [-5.76964934]]\n",
      "MSE: 4.5455453350885735\n",
      "R2score: 0.7444673236414702\n",
      "Explained Variance: 0.7444681691963568\n"
     ]
    }
   ],
   "source": [
    "minibatch_grad_descent(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-Batch size:10000\tEpochs:100\n",
      "Analysis time: 11.616  seconds\n",
      "Theta:[[10.8414851 ]\n",
      " [-0.73599002]\n",
      " [-3.17573544]]\n",
      "MSE: 4.668360672002829\n",
      "R2score: 0.7375631285612196\n",
      "Explained Variance: 0.7375661421850817\n"
     ]
    }
   ],
   "source": [
    "minibatch_grad_descent(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check against linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  [10.84736466] \n",
      "Thetas:  [[ 0.         -0.15561296 -3.3378831 ]]\n",
      "R-Squared:\t\t0.76\n",
      "MSE:\t\t\t4.25\n",
      "Explained Variance:\t0.76\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "reg = lin_reg.fit(X_train_scaled, y_train)\n",
    "print(\"Intercept: \",reg.intercept_,\"\\nThetas: \", reg.coef_)\n",
    "print(\"R-Squared:\\t\\t{0:.2f}\".format(reg.score(X_test_scaled,y_test)))\n",
    "yhat_sk = reg.predict(X_test_scaled)\n",
    "print(\"MSE:\\t\\t\\t{0:.2f}\".format(mean_squared_error(y_test,yhat_sk)))\n",
    "print('Explained Variance:\\t{0:.2f}'.format(explained_variance_score(y_test,yhat_sk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "I was able to achieve good results compared to the linear regression. The MSE & R squared are similar to those found using ordinary least squares regression. The size of the mini-batch affects the overall performance speed since it drives the total number of iterations through the interior for loop.\n",
    "\n",
    "Future improvements to the code would be to switch to a while loop instead of a for loop, monitoring the percent change in the MSE. Currently, eta is a constant and could instead be modeled as a learning schedule. I would also incorporate a max iterations check to prevent the function from running continuously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
